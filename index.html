
<!DOCTYPE HTML PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <title>HmmLab</title>
    <link rel="icon" href="favicon.ico" type="image/x-icon" />
    <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
    <link rel="bookmark" href="favicon.ico" type="image/x-icon" />
    <link rel="stylesheet" type="text/css" href="main.css" />
    <link rel="stylesheet" type="text/css" href="index.css" />

    <script async src="https://www.googletagmanager.com/gtag/js?id=G-TXEVECV8DQ"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-TXEVECV8DQ');
    </script>
</head>
<body>
    
    <div id="wrapper">
        <div id="ict" class="ict" >
<!--             <table><tr>
                <td><a href="image/ict.png"  target="_self">
                    <img src="image/ict.png"  alt="ict" >
                </a></td>
                <td><a href="image/ucas_logo.png"  target="_self">
                    <img src="image/ucas_logo.png"  alt="ict" >
                </a></td>
                </tr></table> -->           
            
        </div>


        <div id="aboutme" class="section">
            <div id="aboutmesectitle" class="sectitle">[HmmLab]</div>
            
            <div id="aboutmecontent" class="seccontent">
                <div id="mypic">
                    <a href="image/xiashihong.webp">
                        <img src="image/xiashihong.webp" alt="ShiHong X" />
                    </a>
                </div>
                <div id="myinfo">

                    <p id="myaffiliation">
                        <br /><br />
                        <b>Shihong Xia</b>
                        <br /><br />
                        Professor
                        <br />
                        <br />
<!--                         <a class="institute" href="http://www.ict.cas.cn/" target="_blank">
                            Institute of Computing Technology
                        </a><a class="institute" target="_blank"></a>, CAS
                        <br /> -->
                     </p>
                    <p id="contacttitle"></p>
                    <p class="mycontact">
                        Email: xsh@ict.ac.cn
                    </p>
                </div>
                <div id="myintro" class="myintro"  target="_blank">
                    <p>
                        Laboratory Introduction:<br/>
                        Our research mainly lies in the intersection among computer graphics, virtual reality, and artificial intelligence, 
                        with a focus on human motion modeling for computer applications. Specifically, we are interested in human motion capture and activity understanding based on deep learning, 
                        motion synthesis and motion control based on generative models, virtual human modeling based on digital twins, 
                        and the application of these techniques to augmented reality, humanoid robotics, and other fields.
                        <br />
                    </p>
                </div>
            </div>
        </div>

        <div id="project" class="section">
            <div id="projsectitle" class="sectitle">[Projects]</div>
            <div id="projects" class="seccontent">  
                
                <div id="projects" class="section"> [2023] </div>
                <!-- AttT2M: Text-Driven Human Motion Generation with Multi-Perspective Attention Mechanism -->
                <div id="AttT2M" class="projitem">
                    <div id="AttT2M" class="projthumbnail">
                        <a href="image/AttT2M.png" target="_self">
                            <img src="image/AttT2M.png" alt=" AttT2M" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://ieeexplore.ieee.org/document/10376515">
                                AttT2M: Text-Driven Human Motion Generation with Multi-Perspective Attention Mechanism
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!--Chongyang Zhong, Lei Hu, Zihao Zhang, Shihong Xia,-->
                            <a class="name" href="https://github.com/ZcyMonkey" target="_blank">Chongyang Zhong </a>,
                            <a class="name" href="https://hlcdyy.github.io/" target="_blank">Lei hu </a>,
                            <a class="name" href="http://zihaozhang.tech/" target="_blank">Zihao Zhang</a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                            
                        </p>
                        <p class="projconference">
                            <a class="name" href="https://iccv2023.thecvf.com/" target="_blank">
                                IEEE International Conference on Computer Vision (ICCV), 2023.</a>
                        </p>
                        <p class="projlinks">
                            <!-- [<a href="https://github.com/NaughtyZZ/3D_facial_shape_attribute_translation_ssgmap">Project Page</a>] -->
                            [<a href="papers/AttT2M_Text-Driven Human Motion Generation with Multi-Perspective Attention Mechanism.pdf">Paper</a>]
                            <!-- [<a href="https://www.bilibili.com/video/BV1bg4y1V7Xi/">BiliBili</a>] -->
                            [<a href="https://github.com/ZcyMonkey/AttT2M">Code</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                
                <!-- Probabilistic Triangulation for uncalibrated multi-view 3D human pose estimation -->
                <div id="Probabilistic_Triangulation" class="projitem">
                    <div id="Probabilistic_Triangulation" class="projthumbnail">
                        <a href="image/Probabilistic_Triangulation.png" target="_self">
                            <img src="image/Probabilistic_Triangulation.png" alt="Probabilistic_Triangulation" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://ieeexplore.ieee.org/document/10376827">
                                Probabilistic Triangulation for uncalibrated multi-view 3D human pose estimation
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!--Boyuan Jiang, Lei Hu, Shihong Xia-->                
                            <a class="name" >Boyuan Jiang</a>,                        
                            <a class="name" href="https://hlcdyy.github.io/" target="_blank">Lei hu </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                            
                        </p>
                        <p class="projconference">
                            <a class="name" href="https://iccv2023.thecvf.com/" target="_blank">
                                IEEE/CVF International Conference on Computer Vision (ICCV), 2023</a>
                        </p>
                        <p class="projlinks">
                            <!-- [<a href="https://github.com/bymaths/probabilistic_triangulation">Project Page</a>] -->
                            [<a href="papers/Probabilistic Triangulation for uncalibrated multi-view 3D human pose estimation.pdf">Paper</a>]
                            <!-- [<a href="https://www.bilibili.com/video/BV1bg4y1V7Xi/">BiliBili</a>] -->
                            [<a href="https://github.com/bymaths/probabilistic_triangulation">Code</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>


                <!-- Unpaired Multi-domain Attribute Translation of 3D Facial Shapes with a Square and Symmetric Geometric Map -->
                <div id="Unpaired_Multi-domain" class="projitem">
                    <div id="Unpaired_Multi-domain" class="projthumbnail">
                        <a href="image/Unpaired_Multi-domain.png" target="_self">
                            <img src="image/Unpaired_Multi-domain.png" alt="Unpaired_Multi-domain" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="http://export.arxiv.org/abs/2308.13245">
                                Unpaired Multi-domain Attribute Translation of 3D Facial Shapes with a Square and Symmetric Geometric Map
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!--Zhenfeng Fan, Zhiheng Zhang, Shuang Yang, Chongyang Zhong, Min Cao, Shihong Xia-->
                            <a class="name" href="https://github.com/NaughtyZZ/" target="_blank">Zhenfeng Fan </a>,
                            <a class="name" >Zhiheng Zhang</a>,
                            <a class="name" >Shuang Yang</a>,
                            <a class="name" href="https://github.com/ZcyMonkey" target="_blank">Chongyang Zhong </a>,
                            <a class="name" >Min Cao</a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                            
                        </p>
                        <p class="projconference">
                            <a class="name" href="https://iccv2023.thecvf.com/" target="_blank">
                                ICCV 2023</a>
                        </p>
                        <p class="projlinks">
                            <!-- [<a href="https://github.com/NaughtyZZ/3D_facial_shape_attribute_translation_ssgmap">Project Page</a>] -->
                            [<a href="papers/Unpaired Multi-domain Attribute Translation of 3D Facial Shapes with a Square and Symmetric Geometric Map.pdf">Paper</a>]
                            <!-- [<a href="https://www.bilibili.com/video/BV1bg4y1V7Xi/">BiliBili</a>] -->
                            [<a href="https://github.com/NaughtyZZ/3D_facial_shape_attribute_translation_ssgmap">Code</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!-- Pose-aware Attention Network for Flexible Motion Retargeting by Body Part -->
                <div id="Pose-aware" class="projitem">
                    <div id="Pose-aware" class="projthumbnail">
                        <a href="image/Pose-aware.png" target="_self">
                            <img src="image/Pose-aware.png" alt="Pose-aware" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://arxiv.org/abs/2306.08006">
                                Pose-aware Attention Network for Flexible Motion Retargeting by Body Part
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!-- Lei Hu, Zihao Zhang, Chongyang Zhong, Boyuan Jiang, Shihong Xia -->
                            <a class="name" href="https://hlcdyy.github.io/" target="_blank">Lei hu </a>,
                            <a class="name" href="http://zihaozhang.tech/" target="_blank">Zihao Zhang</a>,
                            <a class="name" href="https://github.com/ZcyMonkey" target="_blank">Chongyang Zhong </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37086479093" target="_blank">Boyuan Jiang</a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                            
                        </p>
                        <p class="projconference">
                            <a class="name" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=2945" target="_blank">
                                IEEE Transactions on Visualization and Computer Graphics</a> (Volume: 10,26 July 2022)
                        </p>
                        <p class="projlinks">
                            <!-- [<a href="https://github.com/hlcdyy/pan-motion-retargeting">Project Page</a>] -->
                            [<a href="https://HmmLab.github.io/works/papers/Pose-aware Attention Network for Flexible Motion Retargeting by Body Part.pdf">Paper</a>]
                            [<a href="https://www.bilibili.com/video/BV1bg4y1V7Xi/">BiliBili</a>]
                            [<a href="https://github.com/hlcdyy/pan-motion-retargeting">Code</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!--Towards Fine-grained 3D Face Dense Registration: An Optimal Dividing and Diffusing Method. -->
                <div id="Towards_Fine-grained" class="projitem">                   
                    <div id="Towards_Fine-grained" class="projthumbnail">
                        <a href="image/Towards_Fine-grained.png" target="_self">
                            <img src="image/Towards_Fine-grained.png" alt="Towards_Fine-grained" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://arxiv.org/abs/2109.11204">
                                Towards Fine-grained 3D Face Dense Registration: An Optimal Dividing and Diffusing Method
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!--Zhenfeng Fan, Silong Peng, Shihong Xia -->
                            <a href="https://github.com/NaughtyZZ">Zhenfeng Fan </a>,
                            <a >Silong Peng </a>, 
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                        </p>
                        <p class="projconference">
                            <a >International Journal of Computer Vision</a> 
                        <p class="projlinks">
                            <!-- [<a href="https://github.com/NaughtyZZ/3D_face_dense_registration">Project Page</a>] -->
                            [<a href="papers/Towards Fine-grained 3D Face Dense Registration_An Optimal Dividing and Diffusing Method.pdf">Paper</a>]
                            [<a >Video</a>]
                            [<a href="https://github.com/NaughtyZZ/3D_face_dense_registration">Code</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!-- Motif-GCNs With Local and Non-Local Temporal Blocks for Skeleton-Based Action Recognition. -->
                <div id="Motif" class="projitem">
                    <div id="Motif" class="projthumbnail">
                        <a href="https://HmmLab.github.io/works/image/Motif.gif" target="_self">
                            <img src="https://HmmLab.github.io/works/image/Motif.gif" alt="Motif" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <a class="papertitle" href="https://github.com/wenyh1616/SAMotif-GCN">
                                Motif-GCNs With Local and Non-Local Temporal Blocks for Skeleton-Based Action Recognition.
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!-- Yu-Hui Wen, Lin Gao, Hongbo Fu, Fang-Lue Zhang, Shihong Xia, Yong-Jin Liu -->
                            <a class="name" href="https://ieeexplore.ieee.org/author/37089016300" target="_blank">Yu-Hui Wen</a>,
                            <a class="name" href="http://geometrylearning.com/" target="_blank">Lin Gao </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37626240300" target="_blank">Hongbo Fu </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/38474069400" target="_blank">Fang-Lue Zhang </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37279426700" target="_blank">Yong-Jin Liu</a>
                        </p>
                        <p class="projconference">
                            <a class="name" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">
                                IEEE Transactions on Pattern Analysis and Machine Intelligence </a>( Volume: 45, Issue: 2, 01 February 2023)
                        </p>
                        <p class="projlinks">
                            <!-- [<a href="https://github.com/wenyh1616/SAMotif-GCN">Project Page</a>] -->
                            [<a href="https://HmmLab.github.io/works/papers/Motif-GCNs_With_Local_and_Non-Local_Temporal_Blocks_for_Skeleton-Based_Action_Recognition.pdf">Paper</a>]
                            <!-- [Video (<a href="https://www.youtube.com/watch?v=qy2MrNhsoIs">YouTube</a>|<a href="https://www.bilibili.com/video/BV1G24y1d7Tt">BiliBili</a>)] -->
                            [<a href="https://github.com/wenyh1616/SAMotif-GCN">Code</a>] 
                        </p>
                    </div>
                </div>
                
                <!-- Multiscale Mesh Deformation Component Analysis With Attention-Based Autoencoders -->
                <div id="Multiscale" class="projitem">
                    <div id="Multiscale" class="projthumbnail">
                        <a href="image/Multiscale Mesh.gif" target="_self">
                            <img src="image/Multiscale Mesh.gif" alt="Motif" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://ieeexplore.ieee.org/document/9537699">
                                Multiscale Mesh Deformation Component Analysis With Attention-Based Autoencoders
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!-- Jie Yang; Lin Gao; Qingyang Tan; Yi-Hua Huang; Shihong Xia; Yu-Kun Lai -->
                            <a class="name" href="https://ieeexplore.ieee.org/author/37088450605" target="_blank">Jie Yang </a>,
                            <a class="name" href="http://geometrylearning.com/" target="_blank">Lin Gao </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37086567528" target="_blank">Qingyang Tan </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37089542762" target="_blank">Yi-Hua Huang </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/38575316500" target="_blank">Yu-Kun Lai</a>
                        </p>
                        <p class="projconference">
                            <a class="name" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=2945" target="_blank">
                                IEEE Transactions on Visualization and Computer Graphics</a> (Volume: 29, Issue: 2, 01 February 2023)
                        </p>
                        <p class="projlinks">
                            <!-- [Project Page][<a href="https://github.com/wenyh1616/SAMotif-GCN">Project Page</a>] -->
                            [<a href="https://HmmLab.github.io/works/papers/Multiscale_Mesh_Deformation_Component_Analysis_wit.pdf">Paper</a>]
                            [<a href="video/Multiscale Mesh.mp4">Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <div id="projects" class="section"> [2022] </div>
                <!--Spatial-temporal modeling for prediction of stylized human motion. -->
                <div id="Spatial-temporal" class="projitem">                   
                    <div id="Spatial-temporal" class="projthumbnail">
                        <a href="image/Spatial-temporal.jpg" target="_self">
                            <img src="image/Spatial-temporal.jpg" alt="Spatio-temporal" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://www.sciencedirect.com/science/article/pii/S092523122201075X">
                                Spatial-temporal modeling for prediction of stylized human motion
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!-- Chongyang Zhong, Lei Hu, Shihong Xia-->
                            <a class="name" href="https://github.com/ZcyMonkey" target="_blank">Chongyang Zhong </a>,
                            <a class="name" href="https://hlcdyy.github.io/" target="_blank">lei hu </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                            
                            
                        </p>
                        <p class="projconference">
                            <a class="name" href="https://www.sciencedirect.com/journal/neurocomputing" target="_blank">
                                Neurocomputing </a> ( Volume 511, 28 October 2022, Pages 34-42)
                        <p class="projlinks">
                            <!-- [<a>Project Page</a>] -->
                            [<a href="papers/Spatial–temporal modeling for prediction of stylized human motion.pdf">Paper</a>]
                            [<a>Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!--Learning Uncoupled-Modulation CVAE for 3D Action-Conditioned Human Motion Synthesis. -->
                <div id="Learning_Uncoupled-Modulation" class="projitem">                   
                    <div id="Learning_Uncoupled-Modulation" class="projthumbnail">
                        <a href="image/Learning_Uncoupled-Modulation.png" target="_self">
                            <img src="image/Learning_Uncoupled-Modulation.png" alt="Learning_Uncoupled-Modulation" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://link.springer.com/chapter/10.1007/978-3-031-19803-8_42">
                                Learning Uncoupled-Modulation CVAE for 3D Action-Conditioned Human Motion Synthesis
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!-- Chongyang Zhong, Lei Hu, Zihao Zhang & Shihong Xia -->
                            <a class="name" href="https://github.com/ZcyMonkey" target="_blank">Chongyang Zhong </a>,
                            <a class="name" href="https://hlcdyy.github.io/" target="_blank">lei hu </a>,
                            <a class="name" href="http://zihaozhang.tech/" target="_blank">Zihao Zhang </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                            
                            
                        </p>
                        <p class="projconference">
                            <a class="name" href="https://dblp.uni-trier.de/db/conf/eccv/index.html" target="_blank">
                                Computer Vision–ECCV 2022</a> ( LNCS,volume 13681)
                        <p class="projlinks">
                            [<a href="https://github.com/ZcyMonkey/UM-CVAE">Project Page</a>]
                            [<a href="papers/Learning Uncoupled-Modulation CVAE for 3D Action-Conditioned Human Motion Synthesis.pdf">Paper</a>]
                            [<a>Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!-- RAID-Net: Region-Aware Image Deblurring Network Under Guidance of the Image Blur Formulation -->
                <div id="RAID-Net" class="projitem">
                    <div id="RAID-Net" class="projthumbnail">
                        <a href="image/RAID-Net.gif" target="_self">
                            <img src="image/RAID-Net.gif" alt="RAID-Net" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://ieeexplore.ieee.org/document/9840371">
                                RAID-Net: Region-Aware Image Deblurring Network Under Guidance of the Image Blur Formulation
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!-- Lianjun Liao; Zihao Zhang; Shihong Xia -->
                            <a class="name" href="https://ieeexplore.ieee.org/author/37086108917" target="_blank">Lianjun Liao </a>,
                            <a class="name" href="http://zihaozhang.tech/" target="_blank">Zihao Zhang </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                            
                        </p>
                        <p class="projconference">
                            <a class="name" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6287639" target="_blank">
                                IEEE Access </a> (Volume: 10,26 July 2022)
                        </p>
                        <p class="projlinks">
                            <!-- [<a>Project Page</a>] -->
                            [<a href="papers/RAID-Net_ Region-Aware Image Deblurring Network Under Guidance of the Image Blur Formulation.pdf">Paper</a>]
                            [<a href="video/RAID-Net.mp4">Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!-- Neural3Points: Learning to Generate Physically Realistic Full-body Motion for Virtual Reality Users -->
                <div id="Neural3Points" class="projitem">
                    <div id="Pose-aware" class="projthumbnail">
                        <a href="image/Neural3Points.png" target="_self">
                            <img src="image/Neural3Points.png" alt="Pose-aware" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <a class="papertitle" href="https://liamjing.github.io/Neural3Points/">
                                Neural3Points: Learning to Generate Physically Realistic Full-body Motion for Virtual Reality Users
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!-- Yongjing Ye, Libin Liu, Lei Hu, Shihong Xia -->                            
                            <a class="name" href="https://liamjing.github.io/" target="_blank">Yongjing Ye </a>,
                            <a class="name" href="https://libliu.info/" target="_blank">Libin Liu</a>,
                            <a class="name" href="https://hlcdyy.github.io/" target="_blank">lei hu </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                            
                        </p>
                        <p class="projconference">
                            <a class="name" href="https://www.scimagojr.com/journalsearch.php?q=25023&tip=sid" target="_blank">
                                Computer Graphics Forum</a> (Vol 41 Issue 8, Page 183-194 (SCA 2022))
                        </p>
                        <p class="projlinks">
                            [<a href="https://liamjing.github.io/Neural3Points/">Project Page</a>]
                            [<a href="https://HmmLab.github.io/works/papers/Neural3Points_Learning to Generate Physically Realistic Full-body.pdf">Paper</a>]
                            [<a href="https://www.youtube.com/watch?v=Y293EVW5jfM">YouTube</a>|<a href="https://www.bilibili.com/video/BV1KB4y1j7vg/">BiliBili</a>]
                            <!-- [<a href="https://liamjing.github.io/Neural3Points/">Code</a>] -->
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                 <!-- Spatio-Temporal Gating-Adjacency GCN for Human Motion Prediction. -->
                <div id="Spatio-Temporal" class="projitem">                   
                    <div id="Spatio-Temporal" class="projthumbnail">
                        <a href="image/Spatio-Temporal.gif" target="_self">
                            <img src="image/Spatio-Temporal.gif" alt="Spatio-Temporal" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://ieeexplore.ieee.org/document/9879222">
                                Spatio-Temporal Gating-Adjacency GCN for Human Motion Prediction
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!-- Chongyang Zhong; Lei Hu; Zihao Zhang; Yongjing Ye; Shihong Xia -->
                            <a class="name" href="https://github.com/ZcyMonkey" target="_blank">Chongyang Zhong </a>,
                            <a class="name" href="https://hlcdyy.github.io/" target="_blank">lei hu </a>,
                            <a class="name" href="http://zihaozhang.tech/" target="_blank">Zihao Zhang </a>,
                            <a class="name" href="https://liamjing.github.io/" target="_blank">Yongjing Ye </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                            
                        </p>
                        <p class="projconference">
                            <a class="name" href="https://ieeexplore.ieee.org/xpl/conhome/9878378/proceeding" target="_blank">
                                2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) </a> 
                        <p class="projlinks">
                            [<a href="https://github.com/ZcyMonkey/GAGCN">Project Page</a>]
                            [<a href="papers/Spatio-Temporal_Gating-Adjacency_GCN_for_Human_Motion_Prediction.pdf">Paper</a>]
                            [<a href="video/Spatio-Temporal.mp4">Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!-- Active Colorization for Cartoon Line Drawings. -->
                <div id="Active-Colorization" class="projitem">                   
                    <div id="Active-Colorization" class="projthumbnail">
                        <a href="image/Active-Colorization.gif" target="_self">
                            <img src="image/Active-Colorization.gif" alt="Active-Colorization" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://ieeexplore.ieee.org/document/9143503">
                                Active Colorization for Cartoon Line Drawings
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!-- Shu-Yu Chen; Jia-Qi Zhang; Lin Gao; Yue He; Shihong Xia; Min Shi; Fang-Lue Zhang-->
                            <a class="name" href="http://people.geometrylearning.com/csy/" target="_blank">Shu-Yu Chen </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37087232590" target="_blank">Jia-Qi Zhang</a>,
                            <a class="name" href="http://geometrylearning.com/" target="_blank">Lin Gao </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37089217482/" target="_blank">Yue He </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37089216907" target="_blank">Min Shi </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/38474069400" target="_blank">Fang-Lue Zhang </a>
                            
                        </p>
                        <p class="projconference">
                            <a class="name" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=2945" target="_blank">
                                IEEE Transactions on Visualization and Computer Graphics </a> ( Volume: 28, Issue: 2, 01 February 2022)
                        <p class="projlinks">
                            <!-- [<a>Project Page</a>] -->
                            [<a href="papers/Active_Colorization_for_Cartoon_Line_Drawings.pdf">Paper</a>]
                            [<a href="video/Active-Colorization.mp4">Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>              
                
                <div id="projects" class="section"> [2021] </div>
                <!--Combining Recurrent Neural Networks and Adversarial Training for Human Motion Synthesis and Control -->
                <div id="Combining_Recurrent" class="projitem">                   
                    <div id="Combining_Recurrent" class="projthumbnail">
                        <a href="image/Combining_Recurrent.gif" target="_self">
                            <img src="image/Combining_Recurrent.gif" alt="Combining_Recurrent" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://ieeexplore.ieee.org/document/8826012/">
                                Combining Recurrent Neural Networks and Adversarial Training for Human Motion Synthesis and Control
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!-- Zhiyong Wang; Jinxiang Chai; Shihong Xia -->
                            <a class="name" href="https://ieeexplore.ieee.org/author/37088563961" target="_blank">Zhiyong Wang </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37396663100" target="_blank">Jinxiang Chai </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                            
                            
                        </p>
                        <p class="projconference">
                            <a class="name" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=2945" target="_blank">
                                IEEE Transactions on Visualization and Computer Graphics</a> ( Volume: 27, Issue: 1, 01 January 2021)
                        <p class="projlinks">
                            <!-- [<a>Project Page</a>] -->
                            [<a href="papers/Combining_Recurrent_Neural_Networks_and_Adversarial_Training_for_Human_Motion_Synthesis_and_Control.pdf">Paper</a>]
                            [<a href="video/Combining_Recurrent.mp4">Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!--Realtime and Accurate 3D Eye Gaze Capture with DCNN-Based Iris and Pupil Segmentation. -->
                <div id="Realtime_and_Accurate_3D_Eye" class="projitem">                   
                    <div id="Realtime_and_Accurate_3D_Eye" class="projthumbnail">
                        <a href="image/Realtime_and_Accurate_3D_Eye.gif" target="_self">
                            <img src="image/Realtime_and_Accurate_3D_Eye.gif" alt="Realtime_and_Accurate_3D_Eye" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://ieeexplore.ieee.org/document/8818661">
                                Realtime and Accurate 3D Eye Gaze Capture with DCNN-Based Iris and Pupil Segmentation
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!-- Zhiyong Wang; Jinxiang Chai; Shihong Xia-->
                            <a class="name" href="https://ieeexplore.ieee.org/author/37088563961" target="_blank">Zhiyong Wang </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37396663100" target="_blank">Jinxiang Chai </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>       
                        </p>
                        <p class="projconference">
                            <a class="name" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=2945" target="_blank">
                                IEEE Transactions on Visualization and Computer Graphics</a> (Volume: 27, Issue: 1, 01 January 2021)
                        <p class="projlinks">
                            <!-- [<a>Project Page</a>] -->
                            [<a href="papers/Realtime_and_Accurate_3D_Eye_Neural_Networks_and_Adversarial_Training_for_Human_Motion_Synthesis_and_Control.pdf">Paper</a>]
                            [<a>Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!--Sparse Data Driven Mesh Deformation -->
                <div id="Sparse_Data" class="projitem">                   
                    <div id="Sparse_Data" class="projthumbnail">
                        <a href="image/Sparse_Data.gif" target="_self">
                            <img src="image/Sparse_Data.gif" alt="Sparse_Data" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://ieeexplore.ieee.org/document/8839414">
                                Sparse Data Driven Mesh Deformation
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!-- Lin Gao; Yu-Kun Lai; Jie Yang; Ling-Xiao Zhang; Shihong Xia; Leif Kobbelt -->
                            <a class="name" href="http://geometrylearning.com/" target="_blank">Lin Gao </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37088563961" target="_blank">Yu-Kun Lai </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37088450605" target="_blank">Jie Yang </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37088655587" target="_blank">Ling-Xiao Zhang </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37266790600" target="_blank">Leif Kobbelt </a>
                            
                        </p>
                        <p class="projconference">
                            <a class="name" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=2945" target="_blank">
                                IEEE Transactions on Visualization and Computer Graphics</a> (Volume: 27, Issue: 3, 01 March 2021)
                        <p class="projlinks">
                            <!-- [<a>Project Page</a>] -->
                            [<a href="papers/Sparse_Data_Neural_Networks_and_Adversarial_Training_for_Human_Motion_Synthesis_and_Control.pdf">Paper</a>]
                            [<a href="video/Sparse_Data.mp4">Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!--Sequential 3D Human Pose Estimation Using Adaptive Point Cloud Sampling Strategy. -->
                <div id="Sequential_3D_Human_Pose" class="projitem">                   
                    <div id="Sequential_3D_Human_Pose" class="projthumbnail">
                        <a href="image/Sequential_3D_Human_Pose.png" target="_self">
                            <img src="image/Sequential_3D_Human_Pose.png" alt="Sequential_3D_Human_Pose" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://www.ijcai.org/proceedings/2021/184">
                                Sequential 3D Human Pose Estimation Using Adaptive Point Cloud Sampling Strategy
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!-- 	Zihao Zhang, Lei Hu, Xiaoming Deng, Shihong Xia: -->
                            <a class="name" href="http://zihaozhang.tech/" target="_blank">Zihao Zhang </a>,                            
                            <a class="name" href="https://hlcdyy.github.io/" target="_blank">lei hu </a>,
                            <a class="name" href="https://teacher.ucas.ac.cn/~dengxm" target="_blank">Xiaoming Deng</a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                        </p>
                        <p class="projconference">
                            <a class="name" href="https://ijcai-21.org/" target="_blank">
                                IJCAI,</a> (pp. 1330-1337. 2021)
                        <p class="projlinks">
                            <!-- [<a href="https://github.com/Hmslab/Adapose">Project Page</a>] -->
                            [<a href="papers/Sequential_3D_Human_Pose_Estimation_Using_Adaptive_Point_Cloud_Sampling.pdf">Paper</a>]
                            [<a href="https://ijcai-21.org/videos-slides/?video=6405">Video</a>]
                            [<a href="https://github.com/Hmslab/Adapose">Code</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!--融合神经网络与数值计算的人体逆向运动学求解. -->
                <div id="融合" class="projitem">                   
                    <div id="融合" class="projthumbnail">
                        <a href="image/融合.png" target="_self">
                            <img src="image/融合.png" alt="融合" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://hlcdyy.github.io/publication/2021-01-01-MNN">
                                融合神经网络与数值计算的人体逆向运动学求解
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!--胡磊, 张子豪, and 夏时洪-->
                            <a class="name" href="https://hlcdyy.github.io/" target="_blank">胡磊 </a>,
                            <a class="name" href="http://zihaozhang.tech/" target="_blank">张子豪 </a>, 
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">夏时洪</a>
                        </p>
                        <p class="projconference">
                            <a class="name"  target="_blank">
                                中国科学: 数学, 2021 </a> ( Volume: 51, Issue: 1, 2021)
                        <p class="projlinks">
                            [<a >Project Page</a>]
                            [<a href="papers/融合神经网络与数值计算的人体逆向.pdf">Paper</a>]
                            [<a href="https://www.bilibili.com/video/BV1A7411R7Lg/?spm_id_from=333.999.0.0&vd_source=cf809ecf45809233e7f000decbbeb176">Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!--3D-TalkEmo: Learning to Synthesize 3D Emotional Talking Head. -->
                <!-- <div id="3D-TalkEmo" class="projitem">                   
                    <div id="3D-TalkEmo" class="projthumbnail">
                        <a href="image/3D-TalkEmo.png" target="_self">
                            <img src="image/3D-TalkEmo.png" alt="3D-TalkEmo" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle"> -->
                            <!-- 项目网址,目前为论文网址 -->
                            <!-- <a class="papertitle" href="https://arxiv.org/abs/2104.12051">
                                3D-TalkEmo: Learning to Synthesize 3D Emotional Talking Head
                            </a>
                        </p> -->
                        <!-- 作者 -->
                        <!-- <p class="projauthor"> -->
                            <!-- Qianyun Wang, Zhenfeng Fan, Shihong Xia -->
                            <!-- <a >Qianyun Wang </a>,                            
                            <a >Zhenfeng Fan </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                            
                            
                        </p>
                        <p class="projconference">
                            <a >
                                Computer Vision and Pattern Recognition</a> 
                        <p class="projlinks">
                            [<a >Project Page</a>]
                            [<a href="papers/3D-TalkEmo_Learning_to_Synthesize_3D_Emotional_Talking_Head.pdf">Paper</a>]
                            [<a >Video</a>] -->
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        <!-- </p>
                    </div>
                </div>                 -->

                <div id="projects" class="section"> <p></p>[2020]<p></p> </div>
                

                <!-- DeepFaceDrawing: deep generation of face images from sketches -->
                <div id="DeepFaceDrawing" class="projitem">                   
                    <div id="DeepFaceDrawing" class="projthumbnail">
                        <a href="image/DeepFaceDrawing.jpg" target="_self">
                            <img src="image/DeepFaceDrawing.jpg" alt="DeepFaceDrawing" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            
                            <a class="papertitle" href="http://geometrylearning.com/DeepFaceDrawing/">
                                DeepFaceDrawing: deep generation of face images from sketches
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!--Shu-Yu Chen#, Wanchao Su#, Lin Gao, Shihong Xia, Hongbo Fu -->
                            <a class="name" href="http://people.geometrylearning.com/csy/" target="_blank">Shu-Yu Chen </a>,
                            <a >Wanchao Su </a>,
                            <a class="name" href="http://geometrylearning.com/" target="_blank">Lin Gao </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37626240300" target="_blank">Hongbo Fu </a>
                        </p>
                        <p herf="https://www.scimagojr.com/journalsearch.php?q=24972&tip=sid" class="projconference">
                            <a >ACM Transactions on Graphics</a> (SIGGRAPH 2020), 2020, 39(4)
                        <p class="projlinks">
                            <!-- [<a href="http://geometrylearning.com/DeepFaceDrawing/">Project Page</a>] -->
                            [<a href="papers/DeepFaceDrawing_Deep Generation of Face Images from Sketches.pdf">Paper</a>]
                            [<a href="http://geometrylearning.com/DeepFaceDrawing/video/DeepFaceDrawing-video.mp4">Video</a>]
                            [<a href="http://geometrylearning.com/DeepFaceDrawing/">Code</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!-- Deep Line Art Video Colorization with a Few References -->
                <div id="Deep_Line_Art" class="projitem">                   
                    <div id="Deep_Line_Art" class="projthumbnail">
                        <a href="image/Deep_Line_Art.png" target="_self">
                            <img src="image/Deep_Line_Art.png" alt="Deep_Line_Art" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            
                            <a class="papertitle" href="https://arxiv.org/abs/2003.10685">
                                Deep Line Art Video Colorization with a Few References
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!--Min Shi, Jia-Qi Zhang, Shu-Yu Chen, Lin Gao, Yu-Kun Lai, Fang-Lue Zhang-->
                            <a class="name" href="https://ieeexplore.ieee.org/author/37089216907" target="_blank">Min Shi </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37087232590" target="_blank">Jia-Qi Zhang</a>,
                            <a class="name" href="http://people.geometrylearning.com/csy/" target="_blank">Shu-Yu Chen </a>,
                            <a class="name" href="http://geometrylearning.com/" target="_blank">Lin Gao </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37088563961" target="_blank">Yu-Kun Lai </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/38474069400" target="_blank">Fang-Lue Zhang </a>
                        </p>
                        <p  class="projconference">
                            <a >Computer Vision and Pattern Recognition</a>
                        <p class="projlinks">
                            [<a >Project Page</a>]
                            [<a href="papers/Deep Line Art Video Colorization with a Few References.pdf">Paper</a>]
                            [<a href="https://www.bilibili.com/video/av499191000/?vd_source=cf809ecf45809233e7f000decbbeb176">Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!--Weakly Supervised Adversarial Learning for 3D Human Pose Estimation from Point Clouds. -->
                <div id="Weakly_Supervised" class="projitem">                   
                    <div id="Weakly_Supervised" class="projthumbnail">
                        <a href="image/Weakly_Supervised.png" target="_self">
                            <img src="image/Weakly_Supervised.png" alt="Weakly_Supervised" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://ieeexplore.ieee.org/document/8998337">
                                Weakly Supervised Adversarial Learning for 3D Human Pose Estimation from Point Clouds
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!-- Zihao Zhang; Lei Hu; Xiaoming Deng; Shihong Xia-->
                            <a class="name" href="http://zihaozhang.tech/" target="_blank">Zihao Zhang </a>,                            
                            <a class="name" href="https://hlcdyy.github.io/" target="_blank">lei hu </a>,
                            <a class="name" href="https://teacher.ucas.ac.cn/~dengxm" target="_blank">Xiaoming Deng</a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                        </p>
                        <p class="projconference">
                            <a class="name" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=2945" target="_blank">
                                IEEE Transactions on Visualization and Computer Graphics </a> ( Volume: 26, Issue: 5, May 2020)
                        <p class="projlinks">
                            [<a >Project Page</a>]
                            [<a href="papers/Weakly Supervised Adversarial Learning for 3D Human Pose Estimation from Point Clouds.pdf">Paper</a>]
                            [<a href="https://www.bilibili.com/video/BV1A7411R7Lg/?spm_id_from=333.999.0.0&vd_source=cf809ecf45809233e7f000decbbeb176">Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <div id="projects" class="section"><p></p> [2019] </div>
                <!--Temporal Upsampling of Depth Maps Using a Hybrid Camera. -->
                <div id="Temporal_Upsamplinge" class="projitem">                   
                    <div id="Temporal_Upsamplinge" class="projthumbnail">
                        <a href="image/Temporal_Upsamplinge.jpg" target="_self">
                            <img src="image/Temporal_Upsamplinge.jpg" alt="Temporal_Upsamplinge" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://ieeexplore.ieee.org/document/8307258">
                                Temporal Upsampling of Depth Maps Using a Hybrid Camera
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!--Mingze Yuan, Lin Gao*, Hongbo Fu, Shihong Xia-->
                            <a class="name" target="_blank">Mingze Yuan </a>,
                            <a class="name" href="http://geometrylearning.com/" target="_blank">Lin Gao* </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37626240300" target="_blank">Hongbo Fu </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                            
                            
                        </p>
                        <p class="projconference">
                            <a >IEEE Transactions on Visualization and Computer Graphics</a> (IEEE TVCG), 2019, 25(3), 1591-1602
                        <p class="projlinks">
                            [<a >Project Page</a>]
                            [<a href="papers/Temporal Upsampling of Depth Maps Using a Hybrid Camera.pdf">Paper</a>]
                            [<a href="video/Temporal_Upsamplinge.mp4">Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!--Graph CNNs with Motif and Variable Temporal Block for Skeleton-based Action Recognition. -->
                <div id="Graph_CNNs" class="projitem">                   
                    <div id="Graph_CNNs" class="projthumbnail">
                        <a href="image/Graph_CNNs.jpg" target="_self">
                            <img src="image/Graph_CNNs.jpg" alt="Graph_CNNs" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" >
                                Graph CNNs with Motif and Variable Temporal Block for Skeleton-based Action Recognition
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!--Yu-Hui Wen, Lin Gao, Hongbo Fu, Fang-Lue Zhang, Shihong Xia-->
                            <a class="name" target="_blank">Yu-Hui Wen</a>,
                            <a class="name" href="http://geometrylearning.com/" target="_blank">Lin Gao </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37626240300" target="_blank">Hongbo Fu </a>,
                            <a class="name" target="_blank">Fang-Lue Zhang </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                            
                            
                        </p>
                        <p class="projconference">
                            <a >AAAI Conference on Artificial Intelligence (AAAI), 2019 </a> 
                        <p class="projlinks">
                            [<a >Project Page</a>]
                            [<a href="papers/Graph CNNs with Motif and Variable Temporal Block for Skeleton-based Action Recognition.pdf">Paper</a>]
                            [<a >Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!--Data-driven weight optimization for real-time mesh deformation. -->
                <div id="Data-driven_weight" class="projitem">                   
                    <div id="Data-driven_weight" class="projthumbnail">
                        <a href="image/Data-driven_weight.png" target="_self">
                            <img src="image/Data-driven_weight.png" alt="Data-driven_weight" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" >
                                Data-driven weight optimization for real-time mesh deformation
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!-- Yu-jie Yuan, Yu-Kun Lai, Tong Wu, Shihong Xia, Lin Gao -->
                            <a class="name" target="_blank">Yu-jie Yuan </a>,
                            <a class="name" target="_blank">Yu-Kun Lai </a>,
                            <a class="name" target="_blank">Tong Wu </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>,
                            <a class="name" href="http://geometrylearning.com/" target="_blank">Lin Gao </a>
                            
                        </p>
                        <p class="projconference">
                            <a >Graphical Models, 2019, 104. </a> 
                        <p class="projlinks">
                            [<a >Project Page</a>]
                            [<a href="papers/Data-driven weight optimization for real-time mesh deformation.pdf">Paper</a>]
                            [<a >Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <div id="projects" class="section"> [2018] </div>
                 <!--Real-Time 3D Face Reconstruction and Gaze Tracking for Virtual Reality. -->
                <div id="Real-Time_3D_Face" class="projitem">                   
                    <div id="Real-Time_3D_Face" class="projthumbnail">
                        <a href="image/Real-Time_3D_Face.jpg" target="_self">
                            <img src="image/Real-Time_3D_Face.jpg" alt="Real-Time_3D_Face" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://ieeexplore.ieee.org/document/8446494">
                                Real-Time 3D Face Reconstruction and Gaze Tracking for Virtual Reality
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!--Shu-Yu Chen, Lin Gao*, Yu-Kun Lai, Paul L. Rosin, Shihong Xia-->
                            <a class="name" href="http://people.geometrylearning.com/csy/" target="_blank">Shu-Yu Chen </a>,
                            <a class="name" href="http://geometrylearning.com/" target="_blank">Lin Gao* </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37088563961" target="_blank">Yu-Kun Lai </a>,
                            <a >Paul L. Rosin </a>, 
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                            
                            
                        </p>
                        <p class="projconference">
                            <a >IEEE Conference on Virtual Reality</a>(IEEE VR 2018)
                        <p class="projlinks">
                            [<a >Project Page</a>]
                            [<a href="papers/Real-Time 3D Face Reconstruction and Gaze Tracking for Virtual Reality.pdf">Paper</a>]
                            [<a href="video/Real-Time_3D_Face.mp4">Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!--Variational Autoencoders for Deforming 3D Mesh Models. -->
                <div id="Variational_Autoencoderse" class="projitem">       
                    <div id="Variational_Autoencoderse" class="projthumbnail">
                        <a href="image/Variational_Autoencoderse.png" target="_self">
                            <img src="image/Variational_Autoencoderse.png" alt="Variational_Autoencoderse" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://ieeexplore.ieee.org/document/8578710/">
                                Variational Autoencoders for Deforming 3D Mesh Models
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!--Qingyang Tan;Lin Gao;Yu-Kun Lai;Shihong Xia-->
                            <a class="name" href="https://ieeexplore.ieee.org/author/37086567528" target="_blank">Qingyang Tan </a>,
                            <a class="name" href="http://geometrylearning.com/" target="_blank">Lin Gao </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37088563961" target="_blank">Yu-Kun Lai </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                        </p>
                        <p  herf="https://ieeexplore.ieee.org/xpl/conhome/8576498/proceeding" class="projconference">
                            <a >2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</a>
                        <p class="projlinks">
                            [<a >Project Page</a>]
                            [<a href="papers/Variational Autoencoders for Deforming 3D Mesh Models.pdf">Paper</a>]
                            [<a >Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!-- Cascaded 3D Full-Body Pose Regression from Single Depth Image at 100 FPS -->
                <div id="Cascaded_3D_Full-Body" class="projitem">                   
                    <div id="Cascaded_3D_Full-Body" class="projthumbnail">
                        <a href="image/Cascaded_3D_Full-Body.png" target="_self">
                            <img src="image/Cascaded_3D_Full-Body.png" alt="Cascaded_3D_Full-Body" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="http://zihaozhang.tech/wp-content/uploads/2021/06/VR2018.pdf">
                                Cascaded 3D Full-Body Pose Regression from Single Depth Image at 100 FPS
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!--Xia Shihong, Zihao Zhang, and Le Su-->
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>,
                            <a class="name" href="http://zihaozhang.tech/" target="_blank">Zihao Zhang </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37086446969" target="_blank">Le Su </a>
                        </p>
                        <p class="projconference">
                            <a >IEEE Virtual Reality conference </a>(2018): 431-438.
                        <p class="projlinks">
                            [<a >Project Page</a>]
                            [<a href="papers/Cascaded 3D Full-Body Pose Regression from Single Depth Image at 100 FPS.pdf">Paper</a>]
                            [<a >Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>
                
                <div id="projects" class="section"> [2017] </div>
                <!--Data-Driven Shape Interpolation and Morphing Editing. -->
                <div id="Data-Driven_Shape" class="projitem">                   
                    <div id="Data-Driven_Shape" class="projthumbnail">
                        <a href="image/Data-Driven_Shape.png" target="_self">
                            <img src="image/Data-Driven_Shape.png" alt="Data-Driven_Shape" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://ieeexplore.ieee.org/document/8818661">
                                Data-Driven Shape Interpolation and Morphing Editing
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!--Lin Gao, Shu-Yu Chen, Yu-Kun Lai, Shihong Xia:-->
                            <a class="name" href="http://geometrylearning.com/" target="_blank">Lin Gao* </a>,
                            <a class="name" href="http://people.geometrylearning.com/csy/" target="_blank">Shu-Yu Chen </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37088563961" target="_blank">Yu-Kun Lai </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                        </p>
                        <p class="projconference">
                            <a >Computer Graphics Forum 2017</a>
                        <p class="projlinks">
                            [<a >Project Page</a>]
                            [<a href="papers/Data-Driven Shape Interpolation and Morphing Editing.pdf">Paper</a>]
                            [<a href="video/Data-Driven_Shape.mp4">Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!--Rigidity controllable as-rigid-as-possible shape deformation. -->
                 <div id="Rigidity_controllable" class="projitem">                   
                    <div id="Rigidity_controllable" class="projthumbnail">
                        <a href="image/Rigidity_controllable.png" target="_self">
                            <img src="image/Rigidity_controllable.png" alt="Rigidity_controllable" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle">
                                Rigidity controllable as-rigid-as-possible shape deformation
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!--Shu-Yu Chen, Lin Gao*, Yu-Kun Lai, Shihong Xia:-->
                            <a class="name" href="http://people.geometrylearning.com/csy/" target="_blank">Shu-Yu Chen </a>,
                            <a class="name" href="http://geometrylearning.com/" target="_blank">Lin Gao* </a>,                           
                            <a class="name" href="https://ieeexplore.ieee.org/author/37088563961" target="_blank">Yu-Kun Lai </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                        </p>
                        <p class="projconference">
                            <a >Graphical Models 2017</a>
                        <p class="projlinks">
                            [<a >Project Page</a>]
                            [<a href="papers/Rigidity controllable as-rigid-as-possible shape deformation.pdf">Paper</a>]
                            [<a >Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>
                
                <!--Individual 3D Model Estimation for Realtime Human Motion Capture. -->
                <div id="Individual_3D_Model" class="projitem">                   
                    <div id="Individual_3D_Model" class="projthumbnail">
                        <a href="image/Individual_3D_Model.gif" target="_self">
                            <img src="image/Individual_3D_Model.gif" alt="Individual_3D_Model" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://ieeexplore.ieee.org/document/8719117">
                                Individual 3D Model Estimation for Realtime Human Motion Capture
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!--Lianjun Liao; Le Su; Shihong Xia-->
                            <a class="name" href="https://ieeexplore.ieee.org/author/37086108917" target="_blank">Lianjun Liao </a>,
                            <a class="name" href="https://ieeexplore.ieee.org/author/37086446969" target="_blank">Le Su </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                        </p>
                        <p class="projconference">
                            <a href="https://ieeexplore.ieee.org/xpl/conhome/8716287/proceeding">
                                2017 International Conference on Virtual Reality and Visualization (ICVRV)</a>
                        <p class="projlinks">
                            [<a >Project Page</a>]
                            [<a href="papers/Individual_3D_Model_Estimation_for_Realtime_Human_Motion_Capture.pdf">Paper</a>]
                            [<a >Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <div id="projects" class="section"> [2016] </div>
                <!-- Data-driven Inverse Dynamics for Human Motion -->
                <div id="Data-driven_Inverse" class="projitem">                   
                    <div id="Data-driven_Inverse" class="projthumbnail">
                        <a href="image/Data-driven_Inverse.jpg" target="_self">
                            <img src="image/Data-driven_Inverse.jpg" alt="Data-driven_Inverse" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://dl.acm.org/doi/epdf/10.1145/2980179.2982440">
                                Data-driven Inverse Dynamics for Human Motion
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!--Xiaolei Lv, Jinxiang Chai, Shihong Xia-->
                            <a class="name" target="_blank">Xiaolei Lv </a>,
                            <a class="name" target="_blank">Jinxiang Chai </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>                          
                            
                        </p>
                        <p class="projconference">
                            <a >SIGGRAPH Asia 2016</a>
                        <p class="projlinks">
                            [<a >Project Page</a>]
                            [<a href="papers/Data-driven Inverse Dynamics for Human Motion.pdf">Paper</a>]
                            [<a href="video/Data-driven_Inverse.avi">Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!--Realtime 3D Eye Gaze Animation Using a Single RGB Camera. -->
                <div id="Realtime_3D_Eye" class="projitem">                   
                    <div id="Realtime_3D_Eye" class="projthumbnail">
                        <a href="image/Realtime_3D_Eye.png" target="_self">
                            <img src="image/Realtime_3D_Eye.png" alt="Realtime_3D_Eye" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://ieeexplore.ieee.org/document/8818661">
                                Realtime 3D Eye Gaze Animation Using a Single RGB Camera
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!--Congyi Wang, Fuhao Shi, Shihong Xia, Jinxiang Chai-->
                            <a class="name" target="_blank">Congyi Wang </a>,
                            <a class="name" target="_blank">Fuhao Shi </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>,
                            <a class="name" target="_blank">Jinxiang Chai </a>
                            
                        </p>
                        <p class="projconference">
                            <a >ACM Transactions on Graphics (SIGGRAPH), 2016</a>
                        <p class="projlinks">
                            [<a >Project Page</a>]
                            [<a href="papers/Realtime 3D Eye Gaze Animation Using a Single RGB Camera.pdf">Paper</a>]
                            [<a href="video/Realtime_3D_Eye.mp4">Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!--Efficient and Flexible Deformation Representation for Data-Driven Surface Modeling. -->
                <div id="Efficient_and_Flexible" class="projitem">                   
                    <div id="Efficient_and_Flexible" class="projthumbnail">
                        <a href="image/Efficient_and_Flexible.png" target="_self">
                            <img src="image/Efficient_and_Flexible.png" alt="Efficient_and_Flexible" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://www.researchgate.net/publication/305743983_Efficient_and_Flexible_Deformation_Representation_for_Data-Driven_Surface_Modeling">
                                Efficient and Flexible Deformation Representation for Data-Driven Surface Modeling
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!--Lin Gao, Yu-Kun Lai, Dun Liang, Shu-Yu Chen, Shihong Xia-->
                            <a class="name" href="http://geometrylearning.com/" target="_blank">Lin Gao</a>,  
                            <a class="name" href="https://ieeexplore.ieee.org/author/37088563961" target="_blank">Yu-Kun Lai </a>,    
                            <a class="name" target="_blank">Dun Liang </a>,  
                            <a class="name" href="http://people.geometrylearning.com/csy/" target="_blank">Shu-Yu Chen </a>,              
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>
                            
                        </p>
                        <p class="projconference">
                            <a >ACM Transactions on Graphics (SIGGRAPH), 2016</a>
                        <p class="projlinks">
                            [<a >Project Page</a>]
                            [<a href="papers/Efficient and Flexible Deformation Representation for Data-Driven Surface Modeling.pdf">Paper</a>]
                            [<a href="video/Efficient_and_Flexible.mp4">Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>

                <!-- Alignment and Super Pixel Segmentation of RGB-D Video Stream -->
                <div id="Alignment_and_Super" class="projitem">                   
                    <div id="Alignment_and_Super" class="projthumbnail">
                        <a href="image/Alignment_and_Super.jpg" target="_self">
                            <img src="image/Alignment_and_Super.jpg" alt="Alignment_and_Super" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle">
                                Alignment and Super Pixel Segmentation of RGB-D Video Stream
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!--Lianjun Liao, Yongbin Hao, Xiangyang Su, Shihong Xia-->
                            <a class="name" href="https://ieeexplore.ieee.org/author/37086108917" target="_blank">Lianjun Liao </a>,
                            <a class="name" target="_blank">Yongbin Hao </a>,
                            <a class="name" target="_blank">Xiangyang Su </a>,
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>                          
                            
                        </p>
                        <p class="projconference">
                            <a >International Conference on Virtua lReality and Visualization (ICVRV 2016) </a>
                        <p class="projlinks">
                            [<a >Project Page</a>]
                            [<a href="papers/Alignment and Super Pixel Segmentation of RGB-D Video Stream.pdf">Paper</a>]
                            [<a >Video</a>]
                            <!-- [<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page">Code</a>] (Coming soon...) -->
                        </p>
                    </div>
                </div>
                
                <div id="projects" class="section"> [2015] </div>
                <!--Realtime Style Transfer for Unlabeled Heterogeneous Human Motion -->
                <div id="Realtime_Style_Transfer" class="projitem">                   
                    <div id="Realtime_Style_Transfer" class="projthumbnail">
                        <a href="image/Realtime_Style_Transfer.jpg" target="_self">
                            <img src="image/Realtime_Style_Transfer.jpg" alt="Realtime_Style_Transfer" />
                        </a>
                    </div>
                    <div class="projintro">
                        <p class="projtitle">
                            <!-- 项目网址,目前为论文网址 -->
                            <a class="papertitle" href="https://www.researchgate.net/publication/283889632_Realtime_Style_Transfer_for_Unlabeled_Heterogeneous_Human_Motion">
                                Realtime Style Transfer for Unlabeled Heterogeneous Human Motion
                            </a>
                        </p>
                        <!-- 作者 -->
                        <p class="projauthor">
                            <!-- Shihong Xia,Congyi Wang,Jinxiang Chai,Jessica Hodgins -->
                            <a class="name" href="https://people.ucas.ac.cn/~0004712" target="_blank">Shihong Xia </a>,
                            <a class="name" target="_blank">Congyi Wang </a>,
                            <a class="name" target="_blank">Jinxiang Chai </a>,                            
                            <a class="name" target="_blank">Jessica Hodgins </a>
                            
                        </p>
                        <p class="projconference">
                            <a >ACM Transactions on Graphics (SIGGRAPH), 2015</a>
                        <p class="projlinks">
                            [<a >Project Page</a>]
                            [<a href="papers/Realtime Style Transfer for Unlabeled Heterogeneous Human Motion.pdf">Paper</a>]
                            [<a href="https://youtu.be/-c9nqPYtOlg">Video</a>]
                            [<a href="Media/Siggraph_2015_style/dataset only.rar">Dataset</a>] 
                        </p>
                    </div>
                </div>
            </div>            
        </div>
    </div>
</body>
</html>
